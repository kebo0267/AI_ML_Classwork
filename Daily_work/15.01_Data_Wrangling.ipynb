{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "6b8fa3be-89f4-4947-83ce-163b74237c7f",
            "metadata": {
                "cellIdentifier": "6b8fa3be-89f4-4947-83ce-163b74237c7f",
                "id": "6b8fa3be-89f4-4947-83ce-163b74237c7f"
            },
            "source": [
                "# __Data Wrangling__"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "72278e90-5b62-4e4c-9783-13c8de00eac4",
            "metadata": {
                "cellIdentifier": "72278e90-5b62-4e4c-9783-13c8de00eac4",
                "id": "72278e90-5b62-4e4c-9783-13c8de00eac4"
            },
            "source": [
                "## __Agenda__"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "40382cae-3528-4cde-8b67-71c2312017fc",
            "metadata": {
                "cellIdentifier": "40382cae-3528-4cde-8b67-71c2312017fc",
                "id": "40382cae-3528-4cde-8b67-71c2312017fc"
            },
            "source": [
                "- Introduction to Data Wrangling\n",
                "- Data Collection\n",
                "- Data Inspection\n",
                "  * Accessing Rows Using .iloc and .loc\n",
                "  * Checking for Missing Values\n",
                "  * Handling Missing Data\n",
                "- Dealing with Duplicates\n",
                "- Data Cleaning\n",
                "- Data Transformation\n",
                "- Data Binning\n",
                "- Handling Outliers\n",
                "- Pandas Joining Techniques\n",
                "    * Pandas Concatenate\n",
                "    * Pandas Merge Dataframes\n",
                "    * Pandas Join Dataframes\n",
                "- Aggregating Data\n",
                "- Reshaping Data"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "945bea75-2b82-48fd-bce8-d938dac2225f",
            "metadata": {
                "cellIdentifier": "945bea75-2b82-48fd-bce8-d938dac2225f",
                "id": "945bea75-2b82-48fd-bce8-d938dac2225f"
            },
            "source": [
                "## __1. Introduction to Data Wrangling__\n",
                "Data wrangling, also known as data munging or data preprocessing, is the process of cleaning, structuring, and transforming raw data into a format suitable for analysis.\n",
                "- It is a crucial step in the data preparation pipeline, aiming to make the data more accessible, understandable, and ready for various analytical tasks.\n",
                "- It involves dealing with missing values, handling outliers, transforming variables, and merging datasets, among other tasks."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "114565c7-e82d-4fd4-8284-f110283e346d",
            "metadata": {
                "cellIdentifier": "114565c7-e82d-4fd4-8284-f110283e346d",
                "id": "114565c7-e82d-4fd4-8284-f110283e346d"
            },
            "source": [
                "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Introduction.png)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7dbc5dc1-ef65-41f7-825b-2c8f3105d965",
            "metadata": {
                "cellIdentifier": "7dbc5dc1-ef65-41f7-825b-2c8f3105d965",
                "id": "7dbc5dc1-ef65-41f7-825b-2c8f3105d965"
            },
            "source": [
                "## __2. Data Collection:__\n",
                "\n",
                "Data collection is the process of gathering information from diverse sources to build a comprehensive dataset for analysis.\n",
                "- Sources may include databases, APIs (application programming interfaces), spreadsheets, or external files. Effective data collection ensures the availability of relevant and reliable information."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5f48feae-dfed-4fd1-bcc7-bac222ce1e65",
            "metadata": {
                "cellIdentifier": "5f48feae-dfed-4fd1-bcc7-bac222ce1e65",
                "id": "5f48feae-dfed-4fd1-bcc7-bac222ce1e65"
            },
            "source": [
                "### __Loading Data:__\n",
                "Start by loading data into a Pandas DataFrame"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "00c0da67-9f48-46b8-8ce4-3291cdd54eba",
            "metadata": {
                "cellIdentifier": "00c0da67-9f48-46b8-8ce4-3291cdd54eba",
                "id": "00c0da67-9f48-46b8-8ce4-3291cdd54eba"
            },
            "source": [
                "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Loading.png)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "c17ac73f-5252-43e5-ba66-21d40e15d075",
            "metadata": {
                "cellIdentifier": "c17ac73f-5252-43e5-ba66-21d40e15d075",
                "id": "c17ac73f-5252-43e5-ba66-21d40e15d075"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Load the data\n",
                "df = pd.read_csv('HousePrices.csv')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "10b89993-0daa-4cd1-8023-c43c6ca0cb9d",
            "metadata": {
                "cellIdentifier": "10b89993-0daa-4cd1-8023-c43c6ca0cb9d",
                "id": "10b89993-0daa-4cd1-8023-c43c6ca0cb9d"
            },
            "source": [
                "## __3. Data Inspection__\n",
                "It involves exploring the dataset to gain insights into its structure and quality.\n",
                "- This step involves using functions like df.head(), df.info(), and df.describe() to gain insights into the dataset's structure, data types, and statistical summaries. Checking for missing values, outliers, and inconsistencies is crucial to identify potential issues that need addressing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "1d5d0f7e-4a54-4534-b2c0-8a36531abda2",
            "metadata": {
                "cellIdentifier": "1d5d0f7e-4a54-4534-b2c0-8a36531abda2",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 5,
                    "status": "ok",
                    "timestamp": 1716270127003,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "1d5d0f7e-4a54-4534-b2c0-8a36531abda2",
                "outputId": "2894b7d9-09d2-4bf1-b508-892054324404"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                  date      price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
                        "0  2014-05-02 00:00:00   313000.0       3.0       1.50         1340      7912   \n",
                        "1  2014-05-02 00:00:00  2384000.0       5.0       2.50         3650      9050   \n",
                        "2  2014-05-02 00:00:00   342000.0       3.0       2.00         1930     11947   \n",
                        "3  2014-05-02 00:00:00   420000.0       3.0       2.25         2000      8030   \n",
                        "4  2014-05-02 00:00:00   550000.0       4.0       2.50         1940     10500   \n",
                        "\n",
                        "   floors  waterfront  view  condition  sqft_above  sqft_basement  yr_built  \\\n",
                        "0     1.5           0     0          3        1340              0      1955   \n",
                        "1     2.0           0     4          5        3370            280      1921   \n",
                        "2     1.0           0     0          4        1930              0      1966   \n",
                        "3     1.0           0     0          4        1000           1000      1963   \n",
                        "4     1.0           0     0          4        1140            800      1976   \n",
                        "\n",
                        "   yr_renovated                    street       city  statezip country  \n",
                        "0          2005      18810 Densmore Ave N  Shoreline  WA 98133     USA  \n",
                        "1             0           709 W Blaine St    Seattle  WA 98119     USA  \n",
                        "2             0  26206-26214 143rd Ave SE       Kent  WA 98042     USA  \n",
                        "3             0           857 170th Pl NE   Bellevue  WA 98008     USA  \n",
                        "4          1992         9105 170th Ave NE    Redmond  WA 98052     USA  \n",
                        "                     date          price  bedrooms  bathrooms  sqft_living  \\\n",
                        "4595  2014-07-09 00:00:00  308166.666667       3.0       1.75         1510   \n",
                        "4596  2014-07-09 00:00:00  534333.333333       3.0       2.50         1460   \n",
                        "4597  2014-07-09 00:00:00  416904.166667       3.0       2.50         3010   \n",
                        "4598  2014-07-10 00:00:00  203400.000000       4.0       2.00         2090   \n",
                        "4599  2014-07-10 00:00:00  220600.000000       3.0       2.50         1490   \n",
                        "\n",
                        "      sqft_lot  floors  waterfront  view  condition  sqft_above  \\\n",
                        "4595      6360     1.0           0     0          4        1510   \n",
                        "4596      7573     2.0           0     0          3        1460   \n",
                        "4597      7014     2.0           0     0          3        3010   \n",
                        "4598      6630     1.0           0     0          3        1070   \n",
                        "4599      8102     2.0           0     0          4        1490   \n",
                        "\n",
                        "      sqft_basement  yr_built  yr_renovated             street       city  \\\n",
                        "4595              0      1954          1979     501 N 143rd St    Seattle   \n",
                        "4596              0      1983          2009   14855 SE 10th Pl   Bellevue   \n",
                        "4597              0      2009             0   759 Ilwaco Pl NE     Renton   \n",
                        "4598           1020      1974             0  5148 S Creston St    Seattle   \n",
                        "4599              0      1990             0  18717 SE 258th St  Covington   \n",
                        "\n",
                        "      statezip country  \n",
                        "4595  WA 98133     USA  \n",
                        "4596  WA 98007     USA  \n",
                        "4597  WA 98059     USA  \n",
                        "4598  WA 98178     USA  \n",
                        "4599  WA 98042     USA  \n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 4600 entries, 0 to 4599\n",
                        "Data columns (total 18 columns):\n",
                        " #   Column         Non-Null Count  Dtype  \n",
                        "---  ------         --------------  -----  \n",
                        " 0   date           4600 non-null   object \n",
                        " 1   price          4600 non-null   float64\n",
                        " 2   bedrooms       4600 non-null   float64\n",
                        " 3   bathrooms      4600 non-null   float64\n",
                        " 4   sqft_living    4600 non-null   int64  \n",
                        " 5   sqft_lot       4600 non-null   int64  \n",
                        " 6   floors         4600 non-null   float64\n",
                        " 7   waterfront     4600 non-null   int64  \n",
                        " 8   view           4600 non-null   int64  \n",
                        " 9   condition      4600 non-null   int64  \n",
                        " 10  sqft_above     4600 non-null   int64  \n",
                        " 11  sqft_basement  4600 non-null   int64  \n",
                        " 12  yr_built       4600 non-null   int64  \n",
                        " 13  yr_renovated   4600 non-null   int64  \n",
                        " 14  street         4600 non-null   object \n",
                        " 15  city           4600 non-null   object \n",
                        " 16  statezip       4600 non-null   object \n",
                        " 17  country        4600 non-null   object \n",
                        "dtypes: float64(4), int64(9), object(5)\n",
                        "memory usage: 647.0+ KB\n",
                        "None\n",
                        "              price     bedrooms    bathrooms   sqft_living      sqft_lot  \\\n",
                        "count  4.600000e+03  4600.000000  4600.000000   4600.000000  4.600000e+03   \n",
                        "mean   5.519630e+05     3.400870     2.160815   2139.346957  1.485252e+04   \n",
                        "std    5.638347e+05     0.908848     0.783781    963.206916  3.588444e+04   \n",
                        "min    0.000000e+00     0.000000     0.000000    370.000000  6.380000e+02   \n",
                        "25%    3.228750e+05     3.000000     1.750000   1460.000000  5.000750e+03   \n",
                        "50%    4.609435e+05     3.000000     2.250000   1980.000000  7.683000e+03   \n",
                        "75%    6.549625e+05     4.000000     2.500000   2620.000000  1.100125e+04   \n",
                        "max    2.659000e+07     9.000000     8.000000  13540.000000  1.074218e+06   \n",
                        "\n",
                        "            floors   waterfront         view    condition   sqft_above  \\\n",
                        "count  4600.000000  4600.000000  4600.000000  4600.000000  4600.000000   \n",
                        "mean      1.512065     0.007174     0.240652     3.451739  1827.265435   \n",
                        "std       0.538288     0.084404     0.778405     0.677230   862.168977   \n",
                        "min       1.000000     0.000000     0.000000     1.000000   370.000000   \n",
                        "25%       1.000000     0.000000     0.000000     3.000000  1190.000000   \n",
                        "50%       1.500000     0.000000     0.000000     3.000000  1590.000000   \n",
                        "75%       2.000000     0.000000     0.000000     4.000000  2300.000000   \n",
                        "max       3.500000     1.000000     4.000000     5.000000  9410.000000   \n",
                        "\n",
                        "       sqft_basement     yr_built  yr_renovated  \n",
                        "count    4600.000000  4600.000000   4600.000000  \n",
                        "mean      312.081522  1970.786304    808.608261  \n",
                        "std       464.137228    29.731848    979.414536  \n",
                        "min         0.000000  1900.000000      0.000000  \n",
                        "25%         0.000000  1951.000000      0.000000  \n",
                        "50%         0.000000  1976.000000      0.000000  \n",
                        "75%       610.000000  1997.000000   1999.000000  \n",
                        "max      4820.000000  2014.000000   2014.000000  \n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "date              object\n",
                            "price            float64\n",
                            "bedrooms         float64\n",
                            "bathrooms        float64\n",
                            "sqft_living        int64\n",
                            "sqft_lot           int64\n",
                            "floors           float64\n",
                            "waterfront         int64\n",
                            "view               int64\n",
                            "condition          int64\n",
                            "sqft_above         int64\n",
                            "sqft_basement      int64\n",
                            "yr_built           int64\n",
                            "yr_renovated       int64\n",
                            "street            object\n",
                            "city              object\n",
                            "statezip          object\n",
                            "country           object\n",
                            "dtype: object"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Inspecting the first few rows of the DataFrame\n",
                "print(df.head())\n",
                "\n",
                "# Displaying the last few rows of the DataFrame\n",
                "print(df.tail())\n",
                "\n",
                "# Providing information about the DataFrame, including data types and non-null counts\n",
                "print(df.info())\n",
                "\n",
                "# Displaying descriptive statistics of the DataFrame, such as mean, std, min, max, and so on.\n",
                "print(df.describe())\n",
                "\n",
                "# Displaying datatypes of the columns\n",
                "df.dtypes"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "64bb0950-d529-42bb-9c33-ca7c37162d23",
            "metadata": {
                "cellIdentifier": "64bb0950-d529-42bb-9c33-ca7c37162d23",
                "id": "64bb0950-d529-42bb-9c33-ca7c37162d23"
            },
            "source": [
                "### __3.1 Accessing Rows Using .iloc and .loc__\n",
                "Inspecting the dataset involves exploring its content.\n",
                "- Using .iloc and .loc allows you to access specific rows based on integer-location or label-based indexing, respectively."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "564bb6a1-34c3-4a52-8cc8-a1f108c73923",
            "metadata": {
                "cellIdentifier": "564bb6a1-34c3-4a52-8cc8-a1f108c73923",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 400,
                    "status": "ok",
                    "timestamp": 1716270132114,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "564bb6a1-34c3-4a52-8cc8-a1f108c73923",
                "outputId": "3d8414ed-0eac-47f2-a6a8-7a847e5f68bc"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Result for df.iloc[0]:\n",
                        "date              2014-05-02 00:00:00\n",
                        "price                        313000.0\n",
                        "bedrooms                          3.0\n",
                        "bathrooms                         1.5\n",
                        "sqft_living                      1340\n",
                        "sqft_lot                         7912\n",
                        "floors                            1.5\n",
                        "waterfront                          0\n",
                        "view                                0\n",
                        "condition                           3\n",
                        "sqft_above                       1340\n",
                        "sqft_basement                       0\n",
                        "yr_built                         1955\n",
                        "yr_renovated                     2005\n",
                        "street           18810 Densmore Ave N\n",
                        "city                        Shoreline\n",
                        "statezip                     WA 98133\n",
                        "country                           USA\n",
                        "Name: 0, dtype: object\n",
                        "\n",
                        "Result for df.iloc[10]:\n",
                        "date             2014-05-02 00:00:00\n",
                        "price                       463000.0\n",
                        "bedrooms                         3.0\n",
                        "bathrooms                       1.75\n",
                        "sqft_living                     1710\n",
                        "sqft_lot                        7320\n",
                        "floors                           1.0\n",
                        "waterfront                         0\n",
                        "view                               0\n",
                        "condition                          3\n",
                        "sqft_above                      1710\n",
                        "sqft_basement                      0\n",
                        "yr_built                        1948\n",
                        "yr_renovated                    1994\n",
                        "street            Burke-Gilman Trail\n",
                        "city                Lake Forest Park\n",
                        "statezip                    WA 98155\n",
                        "country                          USA\n",
                        "Name: 10, dtype: object\n"
                    ]
                }
            ],
            "source": [
                "# Access the first row using iloc\n",
                "result_iloc_0 = df.iloc[0]\n",
                "\n",
                "# Display the result for df.iloc[0]\n",
                "print(\"Result for df.iloc[0]:\")\n",
                "print(result_iloc_0)\n",
                "print()\n",
                "\n",
                "# Access the eleventh row using iloc\n",
                "result_iloc_10 = df.iloc[10]\n",
                "\n",
                "# Display the result for df.iloc[10]\n",
                "print(\"Result for df.iloc[10]:\")\n",
                "print(result_iloc_10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "871a7c95-b6b5-4c77-b1eb-6b666eff4403",
            "metadata": {
                "cellIdentifier": "871a7c95-b6b5-4c77-b1eb-6b666eff4403",
                "id": "871a7c95-b6b5-4c77-b1eb-6b666eff4403"
            },
            "source": [
                "### __3.2 Checking for Missing Values__\n",
                "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Checking_for_missing_values.png)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "60b83ed8-4871-434d-be6c-bddb84c5d3c5",
            "metadata": {
                "cellIdentifier": "60b83ed8-4871-434d-be6c-bddb84c5d3c5",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 417,
                    "status": "ok",
                    "timestamp": 1716270136314,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "60b83ed8-4871-434d-be6c-bddb84c5d3c5",
                "outputId": "c69ad6c1-2246-4b9d-f514-8a30f7865952"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Missing Values per Column:\n",
                        "date             0\n",
                        "price            0\n",
                        "bedrooms         0\n",
                        "bathrooms        0\n",
                        "sqft_living      0\n",
                        "sqft_lot         0\n",
                        "floors           0\n",
                        "waterfront       0\n",
                        "view             0\n",
                        "condition        0\n",
                        "sqft_above       0\n",
                        "sqft_basement    0\n",
                        "yr_built         0\n",
                        "yr_renovated     0\n",
                        "street           0\n",
                        "city             0\n",
                        "statezip         0\n",
                        "country          0\n",
                        "dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Checking for missing values\n",
                "missing_values = df.isnull().sum()\n",
                "print(\"Missing Values per Column:\")\n",
                "print(missing_values)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f1d116c3-c39c-4442-a791-656739b579c0",
            "metadata": {
                "cellIdentifier": "f1d116c3-c39c-4442-a791-656739b579c0",
                "id": "f1d116c3-c39c-4442-a791-656739b579c0"
            },
            "source": [
                "### __3.3 Handling Missing Data__\n",
                "Handling missing data is crucial for maintaining data integrity. Various approaches include imputation (replacing missing values with estimated values), the removal of records with missing values, or using default values when appropriate.\n",
                "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Handling_missing_data.png)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "089fb326-1568-47de-8b59-f3e52a06992c",
            "metadata": {
                "cellIdentifier": "089fb326-1568-47de-8b59-f3e52a06992c",
                "id": "089fb326-1568-47de-8b59-f3e52a06992c"
            },
            "source": [
                "To handle missing values in numerical columns of the dataset, we utilize `iloc` to select them, excluding text columns. Thus, we focus solely on columns 1 to 14, which do not contain text data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "8cd59b6a-7996-4afd-9a5e-de7b7c509c3b",
            "metadata": {
                "cellIdentifier": "8cd59b6a-7996-4afd-9a5e-de7b7c509c3b",
                "id": "8cd59b6a-7996-4afd-9a5e-de7b7c509c3b",
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                    date      price  bedrooms  bathrooms  sqft_living  \\\n",
                        "0    2014-05-02 00:00:00   313000.0       3.0       1.50         1340   \n",
                        "1    2014-05-02 00:00:00  2384000.0       5.0       2.50         3650   \n",
                        "2    2014-05-02 00:00:00   342000.0       3.0       2.00         1930   \n",
                        "3    2014-05-02 00:00:00   420000.0       3.0       2.25         2000   \n",
                        "4    2014-05-02 00:00:00   550000.0       4.0       2.50         1940   \n",
                        "..                   ...        ...       ...        ...          ...   \n",
                        "195  2014-05-06 00:00:00   515000.0       3.0       2.50         1790   \n",
                        "196  2014-05-06 00:00:00   513000.0       4.0       2.50         2000   \n",
                        "197  2014-05-06 00:00:00   599000.0       4.0       2.25         2260   \n",
                        "198  2014-05-06 00:00:00   685000.0       4.0       2.50         3030   \n",
                        "199  2014-05-06 00:00:00   365000.0       3.0       1.50         1310   \n",
                        "\n",
                        "     sqft_lot  floors  waterfront  view  condition  sqft_above  sqft_basement  \\\n",
                        "0        7912     1.5           0     0          3        1340              0   \n",
                        "1        9050     2.0           0     4          5        3370            280   \n",
                        "2       11947     1.0           0     0          4        1930              0   \n",
                        "3        8030     1.0           0     0          4        1000           1000   \n",
                        "4       10500     1.0           0     0          4        1140            800   \n",
                        "..        ...     ...         ...   ...        ...         ...            ...   \n",
                        "195      7167     2.0           0     0          3        1790              0   \n",
                        "196      5684     2.0           0     0          3        2000              0   \n",
                        "197     29930     2.0           0     0          4        1400            860   \n",
                        "198      7864     2.0           0     0          3        3030              0   \n",
                        "199      8160     1.0           0     0          3        1310              0   \n",
                        "\n",
                        "     yr_built  yr_renovated                    street       city  statezip  \\\n",
                        "0        1955          2005      18810 Densmore Ave N  Shoreline  WA 98133   \n",
                        "1        1921             0           709 W Blaine St    Seattle  WA 98119   \n",
                        "2        1966             0  26206-26214 143rd Ave SE       Kent  WA 98042   \n",
                        "3        1963             0           857 170th Pl NE   Bellevue  WA 98008   \n",
                        "4        1976          1992         9105 170th Ave NE    Redmond  WA 98052   \n",
                        "..        ...           ...                       ...        ...       ...   \n",
                        "195      1989             0          920 221st Ave NE  Sammamish  WA 98074   \n",
                        "196      1996             0          9041 NE 160th Pl    Kenmore  WA 98028   \n",
                        "197      1977             0          16022 SE 43rd St   Bellevue  WA 98006   \n",
                        "198      1999             0           24201 SE 1st Pl  Sammamish  WA 98074   \n",
                        "199      1950          2005      13714 Ashworth Ave N    Seattle  WA 98133   \n",
                        "\n",
                        "    country  \n",
                        "0       USA  \n",
                        "1       USA  \n",
                        "2       USA  \n",
                        "3       USA  \n",
                        "4       USA  \n",
                        "..      ...  \n",
                        "195     USA  \n",
                        "196     USA  \n",
                        "197     USA  \n",
                        "198     USA  \n",
                        "199     USA  \n",
                        "\n",
                        "[200 rows x 18 columns]\n"
                    ]
                }
            ],
            "source": [
                "# Handling missing values using imputation\n",
                "df_filled = df.fillna(df.iloc[:, 1:14].mean())\n",
                "print(df_filled.head(200))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "207d4f88-4ff6-4f86-8037-3e1241168157",
            "metadata": {
                "cellIdentifier": "207d4f88-4ff6-4f86-8037-3e1241168157",
                "id": "207d4f88-4ff6-4f86-8037-3e1241168157"
            },
            "source": [
                "## __4. Dealing with Duplicates__\n",
                "\n",
                "Duplicates in a dataset can introduce bias and errors.\n",
                "- Identifying and handling duplicate records is essential for ensuring accurate analysis and reporting.\n",
                "\n",
                "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Dealing_with_duplicates.png)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "f56205a2-53a6-40ca-9207-c7c453cb8208",
            "metadata": {
                "cellIdentifier": "f56205a2-53a6-40ca-9207-c7c453cb8208",
                "id": "f56205a2-53a6-40ca-9207-c7c453cb8208"
            },
            "outputs": [],
            "source": [
                "# Removing duplicate records\n",
                "df_no_duplicates = df.drop_duplicates()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a8e3791d",
            "metadata": {
                "cellIdentifier": "a8e3791d",
                "id": "a8e3791d"
            },
            "source": [
                "By default, `drop_duplicates()` retains the first occurrence of a duplicate and removes subsequent ones. This behavior can be changed using the `keep` parameter, if specified otherwise."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f606a020-a1a9-4ba6-a8bb-46d86bcb384d",
            "metadata": {
                "cellIdentifier": "f606a020-a1a9-4ba6-a8bb-46d86bcb384d",
                "id": "f606a020-a1a9-4ba6-a8bb-46d86bcb384d"
            },
            "source": [
                "## __5. Data Cleaning__\n",
                "\n",
                "This includes correcting typographical errors, standardizing date formats, and resolving inconsistencies in categorical data labeling.\n",
                "- Standardizing data formats and units ensures consistency and facilitates analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "1a1e06d9-42a4-4845-9ba2-2cdb515a303b",
            "metadata": {
                "cellIdentifier": "1a1e06d9-42a4-4845-9ba2-2cdb515a303b",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 6,
                    "status": "ok",
                    "timestamp": 1716270148785,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "1a1e06d9-42a4-4845-9ba2-2cdb515a303b",
                "outputId": "3c503905-3701-4bc6-b2d1-760e6beb9d8b"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "DataFrame after cleaning data by standardizing formats:\n",
                        "           date         price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
                        "0    2014-05-02  3.130000e+05       3.0       1.50         1340      7912   \n",
                        "1    2014-05-02  2.384000e+06       5.0       2.50         3650      9050   \n",
                        "2    2014-05-02  3.420000e+05       3.0       2.00         1930     11947   \n",
                        "3    2014-05-02  4.200000e+05       3.0       2.25         2000      8030   \n",
                        "4    2014-05-02  5.500000e+05       4.0       2.50         1940     10500   \n",
                        "...         ...           ...       ...        ...          ...       ...   \n",
                        "4595 2014-07-09  3.081667e+05       3.0       1.75         1510      6360   \n",
                        "4596 2014-07-09  5.343333e+05       3.0       2.50         1460      7573   \n",
                        "4597 2014-07-09  4.169042e+05       3.0       2.50         3010      7014   \n",
                        "4598 2014-07-10  2.034000e+05       4.0       2.00         2090      6630   \n",
                        "4599 2014-07-10  2.206000e+05       3.0       2.50         1490      8102   \n",
                        "\n",
                        "      floors  waterfront  view  condition  sqft_above  sqft_basement  \\\n",
                        "0        1.5           0     0          3        1340              0   \n",
                        "1        2.0           0     4          5        3370            280   \n",
                        "2        1.0           0     0          4        1930              0   \n",
                        "3        1.0           0     0          4        1000           1000   \n",
                        "4        1.0           0     0          4        1140            800   \n",
                        "...      ...         ...   ...        ...         ...            ...   \n",
                        "4595     1.0           0     0          4        1510              0   \n",
                        "4596     2.0           0     0          3        1460              0   \n",
                        "4597     2.0           0     0          3        3010              0   \n",
                        "4598     1.0           0     0          3        1070           1020   \n",
                        "4599     2.0           0     0          4        1490              0   \n",
                        "\n",
                        "      yr_built  yr_renovated                    street       city  statezip  \\\n",
                        "0         1955          2005      18810 Densmore Ave N  Shoreline  WA 98133   \n",
                        "1         1921             0           709 W Blaine St    Seattle  WA 98119   \n",
                        "2         1966             0  26206-26214 143rd Ave SE       Kent  WA 98042   \n",
                        "3         1963             0           857 170th Pl NE   Bellevue  WA 98008   \n",
                        "4         1976          1992         9105 170th Ave NE    Redmond  WA 98052   \n",
                        "...        ...           ...                       ...        ...       ...   \n",
                        "4595      1954          1979            501 N 143rd St    Seattle  WA 98133   \n",
                        "4596      1983          2009          14855 SE 10th Pl   Bellevue  WA 98007   \n",
                        "4597      2009             0          759 Ilwaco Pl NE     Renton  WA 98059   \n",
                        "4598      1974             0         5148 S Creston St    Seattle  WA 98178   \n",
                        "4599      1990             0         18717 SE 258th St  Covington  WA 98042   \n",
                        "\n",
                        "     country  \n",
                        "0        USA  \n",
                        "1        USA  \n",
                        "2        USA  \n",
                        "3        USA  \n",
                        "4        USA  \n",
                        "...      ...  \n",
                        "4595     USA  \n",
                        "4596     USA  \n",
                        "4597     USA  \n",
                        "4598     USA  \n",
                        "4599     USA  \n",
                        "\n",
                        "[4600 rows x 18 columns]\n"
                    ]
                }
            ],
            "source": [
                "# Cleaning data by standardizing formats\n",
                "df['date'] = pd.to_datetime(df['date'])\n",
                "# Displaying the DataFrame after cleaning\n",
                "print(\"DataFrame after cleaning data by standardizing formats:\")\n",
                "print(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2bee3e01-85d1-49c4-b598-6faa4a0e13ae",
            "metadata": {
                "cellIdentifier": "2bee3e01-85d1-49c4-b598-6faa4a0e13ae",
                "id": "2bee3e01-85d1-49c4-b598-6faa4a0e13ae"
            },
            "source": [
                "## __6. Data Transformation__\n",
                "\n",
                "Data transformation includes converting data types, creating new features through feature engineering, and normalizing or scaling numeric values as needed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "1f9034ee-a8e8-4bbf-9564-3ebba6ae992f",
            "metadata": {
                "cellIdentifier": "1f9034ee-a8e8-4bbf-9564-3ebba6ae992f",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 372,
                    "status": "ok",
                    "timestamp": 1716270153452,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "1f9034ee-a8e8-4bbf-9564-3ebba6ae992f",
                "outputId": "1467a7fa-bb46-4b9f-f8cf-46b4c386c4ab"
            },
            "outputs": [],
            "source": [
                "# Creating a new feature and normalizing numeric values\n",
                "# Check if 'price' column exists in the DataFrame\n",
                "import numpy as np\n",
                "if 'price' in df.columns:\n",
                "    # Use the natural logarithm to create a new feature 'Log_Price'\n",
                "    df['Log_Price'] = df['price'].apply(lambda x: np.log(x))\n",
                "\n",
                "    # Normalize 'price' column and create a new feature 'Normalized_Price'\n",
                "    df['Normalized_Price'] = (df['price'] - df['price'].min()) / (df['price'].max() - df['price'].min())\n",
                "\n",
                "    # Displaying the DataFrame with the new features\n",
                "    print(\"DataFrame with new features:\")\n",
                "    print(df)\n",
                "else:\n",
                "    print(\"The 'price' column does not exist in the DataFrame.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1ee6cb49-8f47-4f7e-89a7-973ca1e2c940",
            "metadata": {
                "cellIdentifier": "1ee6cb49-8f47-4f7e-89a7-973ca1e2c940",
                "id": "1ee6cb49-8f47-4f7e-89a7-973ca1e2c940"
            },
            "source": [
                "## __7. Data Binning__\n",
                "Data binning, also known as discretization, is a technique in data transformation to convert continuous numerical data into discrete bins or intervals.\n",
                "- This process helps simplify the analysis of trends, handle outliers, and make data more suitable for certain types of analyses or machine learning algorithms.\n",
                "- It involves grouping numeric values into predefined ranges, creating a categorical representation of the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "70655820-f5ee-406c-9972-c4c689380dd8",
            "metadata": {
                "cellIdentifier": "70655820-f5ee-406c-9972-c4c689380dd8",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 363,
                    "status": "ok",
                    "timestamp": 1716270157265,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "70655820-f5ee-406c-9972-c4c689380dd8",
                "outputId": "75f63d20-e350-406b-8dbf-5ffde4213aac"
            },
            "outputs": [],
            "source": [
                "# Data Binning: Creating bins for the 'price' column\n",
                "# Check if 'price' column exists in the DataFrame\n",
                "if 'price' in df.columns:\n",
                "    # Define bin edges\n",
                "    bin_edges = [0, 100, 200, 300, 400, 500, np.inf]  # Adjust bin edges as needed\n",
                "\n",
                "    # Define bin labels\n",
                "    bin_labels = ['0-100', '101-200', '201-300', '301-400', '401-500', '501+']\n",
                "\n",
                "    # Create a new categorical column 'Price_Category' based on binning\n",
                "    df['Price_Category'] = pd.cut(df['price'], bins=bin_edges, labels=bin_labels, right=False)\n",
                "\n",
                "    # Displaying the DataFrame with the new 'Price_Category' column\n",
                "    print(\"DataFrame with Price_Category column:\")\n",
                "    print(df)\n",
                "else:\n",
                "    print(\"The 'price' column does not exist in the DataFrame.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c4db68b9-d94c-42f6-b87f-5e7b87b73584",
            "metadata": {
                "cellIdentifier": "c4db68b9-d94c-42f6-b87f-5e7b87b73584",
                "id": "c4db68b9-d94c-42f6-b87f-5e7b87b73584"
            },
            "source": [
                "## __8. Handling Outliers__\n",
                "\n",
                "Outliers can significantly impact analysis and modeling. Identifying and addressing outliers is crucial for maintaining the accuracy of results.\n",
                "\n",
                "**Winsorization:** It is the transformation of statistics by limiting extreme values in the statistical data to reduce the effect of possibly spurious outliers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "c41a7cae-8caf-494d-a4bb-89f128cb15d1",
            "metadata": {
                "cellIdentifier": "c41a7cae-8caf-494d-a4bb-89f128cb15d1",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 1033,
                    "status": "ok",
                    "timestamp": 1716270161732,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "c41a7cae-8caf-494d-a4bb-89f128cb15d1",
                "outputId": "0129200b-3860-4928-bd0e-c45c9f8d28f3",
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Handling outliers by winsorizing\n",
                "from scipy.stats.mstats import winsorize\n",
                "\n",
                "# Check if 'price' column exists in the DataFrame\n",
                "if 'price' in df.columns:\n",
                "    # Winsorizing the 'price' column with limits [0.05, 0.05]\n",
                "    df['Winsorized_Price'] = winsorize(df['price'], limits=[0.05, 0.05])\n",
                "\n",
                "    # Displaying the DataFrame with the winsorized column\n",
                "    print(\"DataFrame with winsorized column:\")\n",
                "    print(df)\n",
                "else:\n",
                "    print(\"The 'price' column does not exist in the DataFrame.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f451b3ac-5ee5-4812-b42a-b8216f86680e",
            "metadata": {
                "cellIdentifier": "f451b3ac-5ee5-4812-b42a-b8216f86680e",
                "id": "f451b3ac-5ee5-4812-b42a-b8216f86680e"
            },
            "source": [
                "## __9. Pandas Joining Techniques__"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1934fad9-66cc-481b-a4d6-257d2664668e",
            "metadata": {
                "cellIdentifier": "1934fad9-66cc-481b-a4d6-257d2664668e",
                "id": "1934fad9-66cc-481b-a4d6-257d2664668e",
                "tags": []
            },
            "source": [
                "Pandas provides various joining techniques, such as merging, joining, and concatenating, which allow datasets to be combined using one or more keys. Each method has unique behaviors and applications.\n",
                "\n",
                "\n",
                "- **Concatenate**: It appends DataFrames vertically or horizontally, offering a straightforward way to combine datasets with distinct columns or indices without regard for overlapping keys or index values.\n",
                "\n",
                "- **Merge**: It combines DataFrames by aligning columns with shared keys, allowing for detailed control over overlapping column names and the use of multiple keys.\n",
                "\n",
                "- **Join**: It aligns DataFrames based on their index values, making it ideal for coordinating data with corresponding indices.\n",
                "\n",
                "These techniques are essential for integrating and analyzing different datasets. They enable a thorough understanding and help in making informed decisions in data-driven applications."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9a660a46-dab3-439b-b4cb-6164534b1b09",
            "metadata": {
                "cellIdentifier": "9a660a46-dab3-439b-b4cb-6164534b1b09",
                "id": "9a660a46-dab3-439b-b4cb-6164534b1b09"
            },
            "source": [
                "### __9.1 Pandas Concatenate__\n",
                "\n",
                "- The __pd.concat()__ method combines DataFrames along rows or columns, preserving indices and columns.\n",
                "- Specify axis=0 to concatenate along rows (vertical concatenation) or axis=1 to concatenate along columns (horizontal concatenation)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "004aca8e-fbaa-491d-bba2-c2a1da986f55",
            "metadata": {
                "cellIdentifier": "004aca8e-fbaa-491d-bba2-c2a1da986f55",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 342,
                    "status": "ok",
                    "timestamp": 1716270167186,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "004aca8e-fbaa-491d-bba2-c2a1da986f55",
                "outputId": "382c18b5-3500-4b91-8234-56263e73750a",
                "tags": []
            },
            "outputs": [],
            "source": [
                "df1 = pd.DataFrame(\n",
                "   {\n",
                "       \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
                "       \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
                "       \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
                "       \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
                "   },\n",
                "   index=[0, 1, 2, 3],\n",
                ")\n",
                "\n",
                "df2 = pd.DataFrame(\n",
                "   {\n",
                "       \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n",
                "       \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n",
                "       \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n",
                "       \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n",
                "   },\n",
                "   index=[4, 5, 6, 7],\n",
                ")\n",
                "\n",
                "df3 = pd.DataFrame(\n",
                "   {\n",
                "       \"A\": [\"A8\", \"A9\", \"A10\", \"A11\"],\n",
                "       \"B\": [\"B8\", \"B9\", \"B10\", \"B11\"],\n",
                "       \"C\": [\"C8\", \"C9\", \"C10\", \"C11\"],\n",
                "       \"D\": [\"D8\", \"D9\", \"D10\", \"D11\"],\n",
                "   },\n",
                "   index=[8, 9, 10, 11],\n",
                ")\n",
                "\n",
                "frames = [df1, df2, df3]\n",
                "Result = pd.concat(frames)\n",
                "print(Result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "360f2a13-9823-4e8d-8744-df1b38d653e5",
            "metadata": {
                "cellIdentifier": "360f2a13-9823-4e8d-8744-df1b38d653e5",
                "id": "360f2a13-9823-4e8d-8744-df1b38d653e5"
            },
            "source": [
                "The pictorial representation of the above output is as shown below:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7082e7a5-ee71-457e-a8cb-4292640c3923",
            "metadata": {
                "cellIdentifier": "7082e7a5-ee71-457e-a8cb-4292640c3923",
                "id": "7082e7a5-ee71-457e-a8cb-4292640c3923"
            },
            "source": [
                "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Concatenate.png)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6b37b5df-80fb-45d7-812d-a44fb2f4c7c4",
            "metadata": {
                "cellIdentifier": "6b37b5df-80fb-45d7-812d-a44fb2f4c7c4",
                "id": "6b37b5df-80fb-45d7-812d-a44fb2f4c7c4"
            },
            "source": [
                "Here's another example illustrating concatenation along both the vertical and horizontal axes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "06d15115-eaa1-48ad-ac7a-956833601ca8",
            "metadata": {
                "cellIdentifier": "06d15115-eaa1-48ad-ac7a-956833601ca8",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 395,
                    "status": "ok",
                    "timestamp": 1716270171631,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "06d15115-eaa1-48ad-ac7a-956833601ca8",
                "outputId": "cbc38373-58b3-4b95-930f-7989a35f0789",
                "tags": []
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Create two sample DataFrames\n",
                "df1 = pd.DataFrame({'A': [1, 2, 3],\n",
                "                    'B': [4, 5, 6]})\n",
                "\n",
                "df2 = pd.DataFrame({'A': [7, 8, 9],\n",
                "                    'B': [10, 11, 12]})\n",
                "\n",
                "# Concatenate along rows (stack vertically)\n",
                "Result_row = pd.concat([df1, df2], axis=0)\n",
                "\n",
                "# Concatenate along columns (stack horizontally)\n",
                "Result_column = pd.concat([df1, df2], axis=1)\n",
                "\n",
                "print(\"\\nDataframe 1:\")\n",
                "print(df1)\n",
                "print(\"\\nDataframe 2:\")\n",
                "print(df2)\n",
                "\n",
                "print(\"\\nConcatenated along rows:\")\n",
                "print(Result_row)\n",
                "\n",
                "print(\"\\nConcatenated along columns:\")\n",
                "print(Result_column)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "13f708ab-522d-48d2-9a98-f1bb46b50a0a",
            "metadata": {
                "cellIdentifier": "13f708ab-522d-48d2-9a98-f1bb46b50a0a",
                "id": "13f708ab-522d-48d2-9a98-f1bb46b50a0a"
            },
            "source": [
                "### __9.2 Pandas Merge DataFrames__\n",
                "\n",
                "- Utilize the  **pd.merge()** method to merge DataFrames based on specific keys or columns.\n",
                "- Specify the join type in Pandas merge, which controls how rows from two DataFrames are combined.\n",
                "- This ensures data alignment and prevents unintended outcomes.\n",
                "- Choose the appropriate `how` parameter to specify the type of join.\n",
                "- Specify the `on` parameter to indicate the column(s) to merge on.\n",
                "\n",
                "\n",
                "\n",
                "**Types of Pandas Join**\n",
                "\n",
                "There are various join logics available to merge Pandas DataFrames:\n",
                "\n",
                "- Full Outer Join: It merges all rows from both DataFrames, using NaN to fill in missing values when no match is found.\n",
                "\n",
                "- Inner Join: It combines matching rows from DataFrame 1 and DataFrame 2 based on a common key column.\n",
                "\n",
                "- Right Join: It retains all rows from the right DataFrame, merges on common keys, and fills missing values with NaN.\n",
                "\n",
                "- Left Join: It retains all rows from the left DataFrame, merging matching rows from the right and filling unmatched values with NaN.\n",
                "\n",
                "- Cross: It creates the cartesian product of the rows of both frames."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "62000948-dd8d-4cf0-be84-914f46d1ba36",
            "metadata": {
                "cellIdentifier": "62000948-dd8d-4cf0-be84-914f46d1ba36",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 5,
                    "status": "ok",
                    "timestamp": 1716270174933,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "62000948-dd8d-4cf0-be84-914f46d1ba36",
                "outputId": "3512663f-887f-404b-e22b-2f9d6a40baa4",
                "tags": []
            },
            "outputs": [],
            "source": [
                "left = pd.DataFrame(\n",
                "   {\n",
                "      \"key1\": [\"K0\", \"K0\", \"K1\", \"K2\"],\n",
                "      \"key2\": [\"K0\", \"K1\", \"K0\", \"K1\"],\n",
                "      \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
                "      \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
                "   }\n",
                ")\n",
                "right = pd.DataFrame(\n",
                "   {\n",
                "      \"key1\": [\"K0\", \"K1\", \"K1\", \"K2\"],\n",
                "      \"key2\": [\"K0\", \"K0\", \"K0\", \"K0\"],\n",
                "      \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
                "      \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
                "   }\n",
                ")\n",
                "print(\"\\nDataframe 1:\")\n",
                "print(left)\n",
                "print(\"\\nDataframe 2:\")\n",
                "print(right)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "93b2aedb-9813-4957-abc0-23dda5a4b17d",
            "metadata": {
                "cellIdentifier": "93b2aedb-9813-4957-abc0-23dda5a4b17d",
                "id": "93b2aedb-9813-4957-abc0-23dda5a4b17d"
            },
            "source": [
                "**Full Outer Join**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "85a8fd44-3c14-4faf-9753-0ddeedc55925",
            "metadata": {
                "cellIdentifier": "85a8fd44-3c14-4faf-9753-0ddeedc55925",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 348,
                    "status": "ok",
                    "timestamp": 1716270179066,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "85a8fd44-3c14-4faf-9753-0ddeedc55925",
                "outputId": "cf8a185e-7b34-453d-cd13-24756240def9",
                "tags": []
            },
            "outputs": [],
            "source": [
                "Result = pd.merge(left, right, how=\"outer\", on=[\"key1\", \"key2\"])\n",
                "print(Result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ef9ebdfa-5739-4e50-bf42-c6452004f5c0",
            "metadata": {
                "cellIdentifier": "ef9ebdfa-5739-4e50-bf42-c6452004f5c0",
                "id": "ef9ebdfa-5739-4e50-bf42-c6452004f5c0"
            },
            "source": [
                "The pictorial representation of the above output is as shown below:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7fa36117-f760-474e-ad8f-c96136818316",
            "metadata": {
                "cellIdentifier": "7fa36117-f760-474e-ad8f-c96136818316",
                "id": "7fa36117-f760-474e-ad8f-c96136818316",
                "tags": []
            },
            "source": [
                "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/outer_merge.png)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0dc145eb-7459-4e26-9808-dc887ebe8f19",
            "metadata": {
                "cellIdentifier": "0dc145eb-7459-4e26-9808-dc887ebe8f19",
                "id": "0dc145eb-7459-4e26-9808-dc887ebe8f19"
            },
            "source": [
                "**Inner Join**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "d4a9928b-d4a6-4eba-8e90-c8e078aa6353",
            "metadata": {
                "cellIdentifier": "d4a9928b-d4a6-4eba-8e90-c8e078aa6353",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 354,
                    "status": "ok",
                    "timestamp": 1716270182977,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "d4a9928b-d4a6-4eba-8e90-c8e078aa6353",
                "outputId": "6d6a7202-c35a-473f-d786-058cf8904ee0",
                "tags": []
            },
            "outputs": [],
            "source": [
                "Result = pd.merge(left, right, how=\"inner\", on=[\"key1\", \"key2\"])\n",
                "print(Result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dbc6f1fe-3774-46d2-bf2c-ff780e5822d2",
            "metadata": {
                "cellIdentifier": "dbc6f1fe-3774-46d2-bf2c-ff780e5822d2",
                "id": "dbc6f1fe-3774-46d2-bf2c-ff780e5822d2"
            },
            "source": [
                "The pictorial representation of the above output is as shown below:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "88e47df6-eadb-4e13-8037-ad9647aec58c",
            "metadata": {
                "cellIdentifier": "88e47df6-eadb-4e13-8037-ad9647aec58c",
                "id": "88e47df6-eadb-4e13-8037-ad9647aec58c"
            },
            "source": [
                "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/merge_inner.png)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9fdb6397-7fea-444d-aca6-6ce223feeba1",
            "metadata": {
                "cellIdentifier": "9fdb6397-7fea-444d-aca6-6ce223feeba1",
                "id": "9fdb6397-7fea-444d-aca6-6ce223feeba1"
            },
            "source": [
                "**Right Join**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "1493890b-2736-4b5a-923f-fda64961f310",
            "metadata": {
                "cellIdentifier": "1493890b-2736-4b5a-923f-fda64961f310",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 4,
                    "status": "ok",
                    "timestamp": 1716270185725,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "1493890b-2736-4b5a-923f-fda64961f310",
                "outputId": "bb15574e-37b3-4f95-b82a-a7812c1186a3",
                "tags": []
            },
            "outputs": [],
            "source": [
                "Result = pd.merge(left, right, how=\"right\", on=[\"key1\", \"key2\"])\n",
                "print(Result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f637684a-a4f0-49d3-b90d-550ca000477b",
            "metadata": {
                "cellIdentifier": "f637684a-a4f0-49d3-b90d-550ca000477b",
                "id": "f637684a-a4f0-49d3-b90d-550ca000477b"
            },
            "source": [
                "The pictorial representation of the above output is as shown below:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b1509c03-075b-44f2-8b4f-69fc2b25e47c",
            "metadata": {
                "cellIdentifier": "b1509c03-075b-44f2-8b4f-69fc2b25e47c",
                "id": "b1509c03-075b-44f2-8b4f-69fc2b25e47c"
            },
            "source": [
                "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/merge_right.png)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "85138b91-2fa0-4f90-bac6-c778f2939854",
            "metadata": {
                "cellIdentifier": "85138b91-2fa0-4f90-bac6-c778f2939854",
                "id": "85138b91-2fa0-4f90-bac6-c778f2939854"
            },
            "source": [
                "**Left Join**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "ffca37c3-ee9f-4b73-9a2f-06eadc005ad6",
            "metadata": {
                "cellIdentifier": "ffca37c3-ee9f-4b73-9a2f-06eadc005ad6",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 6,
                    "status": "ok",
                    "timestamp": 1716270188451,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "ffca37c3-ee9f-4b73-9a2f-06eadc005ad6",
                "outputId": "efadf004-4b30-48b6-fdc3-db6490b9437a",
                "tags": []
            },
            "outputs": [],
            "source": [
                "Result = pd.merge(left, right, how=\"left\", on=[\"key1\", \"key2\"])\n",
                "print(Result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "08141c76-43c2-4ec2-9f89-4711dd84d92c",
            "metadata": {
                "cellIdentifier": "08141c76-43c2-4ec2-9f89-4711dd84d92c",
                "id": "08141c76-43c2-4ec2-9f89-4711dd84d92c"
            },
            "source": [
                "The pictorial representation of the above output is as shown below:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5a2da1b4-6afb-4dc4-8a1f-4add8043766a",
            "metadata": {
                "cellIdentifier": "5a2da1b4-6afb-4dc4-8a1f-4add8043766a",
                "id": "5a2da1b4-6afb-4dc4-8a1f-4add8043766a"
            },
            "source": [
                "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/merge_letf.png)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "89841db3-e351-4c66-8959-ce82465fbf9a",
            "metadata": {
                "cellIdentifier": "89841db3-e351-4c66-8959-ce82465fbf9a",
                "id": "89841db3-e351-4c66-8959-ce82465fbf9a",
                "tags": []
            },
            "source": [
                "**Cross**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "e2810f86-88ed-48b3-8f53-380370cdb0fd",
            "metadata": {
                "cellIdentifier": "e2810f86-88ed-48b3-8f53-380370cdb0fd",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 3,
                    "status": "ok",
                    "timestamp": 1716270190596,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "e2810f86-88ed-48b3-8f53-380370cdb0fd",
                "outputId": "0e3a9076-2a11-488b-f507-17f772d89070",
                "tags": []
            },
            "outputs": [],
            "source": [
                "Result = pd.merge(left, right, how=\"cross\")\n",
                "print(Result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d260fabd-018a-400c-94e0-c12cc3e961aa",
            "metadata": {
                "cellIdentifier": "d260fabd-018a-400c-94e0-c12cc3e961aa",
                "id": "d260fabd-018a-400c-94e0-c12cc3e961aa"
            },
            "source": [
                "The pictorial representation of the above output is as shown below:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f7b88ebf-5a73-4519-8062-1f78c015ed4d",
            "metadata": {
                "cellIdentifier": "f7b88ebf-5a73-4519-8062-1f78c015ed4d",
                "id": "f7b88ebf-5a73-4519-8062-1f78c015ed4d"
            },
            "source": [
                "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/merge_cross.png)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "20e46ed0-fb3d-41bf-9707-3d3f84e3b2b8",
            "metadata": {
                "cellIdentifier": "20e46ed0-fb3d-41bf-9707-3d3f84e3b2b8",
                "id": "20e46ed0-fb3d-41bf-9707-3d3f84e3b2b8"
            },
            "source": [
                "### __9.3 Pandas Join DataFrames__\n",
                "\n",
                "- Use the __join()__ method to join DataFrames based on their indices\n",
                "- Specify the `how` parameter to determine the type of join, similar to __pd.merge()__\n",
                "- Use the `on` parameter if joining on specific columns, or simply call __join()__ without parameters to perform a simple index-based join\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "54e53e3d-c797-4625-bd00-bb123e44c032",
            "metadata": {
                "cellIdentifier": "54e53e3d-c797-4625-bd00-bb123e44c032",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 4,
                    "status": "ok",
                    "timestamp": 1716270193209,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "54e53e3d-c797-4625-bd00-bb123e44c032",
                "outputId": "8ac9639a-f57c-43d2-a6bb-bb9d42b403ed",
                "tags": []
            },
            "outputs": [],
            "source": [
                "left = pd.DataFrame(\n",
                "    {\n",
                "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
                "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
                "        \"key\": [\"K0\", \"K1\", \"K0\", \"K1\"],\n",
                "    }\n",
                ")\n",
                "right = pd.DataFrame({\"C\": [\"C0\", \"C1\"],\n",
                "                      \"D\": [\"D0\", \"D1\"]},\n",
                "                      index=[\"K0\", \"K1\"])\n",
                "\n",
                "Result = left.join(right, on=\"key\")\n",
                "print(Result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c02e6757-b102-4f4e-b1a0-e89d62ddc1e9",
            "metadata": {
                "cellIdentifier": "c02e6757-b102-4f4e-b1a0-e89d62ddc1e9",
                "id": "c02e6757-b102-4f4e-b1a0-e89d62ddc1e9"
            },
            "source": [
                "The pictorial representation of the above output is as shown below:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a935373f-0d5d-4978-aa87-e251784862c8",
            "metadata": {
                "cellIdentifier": "a935373f-0d5d-4978-aa87-e251784862c8",
                "id": "a935373f-0d5d-4978-aa87-e251784862c8"
            },
            "source": [
                "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/join.png)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9b3783f5-c4a8-49bb-bafb-cd05c6b300a4",
            "metadata": {
                "cellIdentifier": "9b3783f5-c4a8-49bb-bafb-cd05c6b300a4",
                "id": "9b3783f5-c4a8-49bb-bafb-cd05c6b300a4"
            },
            "source": [
                "## __10. Aggregating Data__\n",
                "\n",
                "Aggregating data involves summarizing or grouping data based on specific criteria. This is useful for creating meaningful insights and reducing data dimensionality.\n",
                "\n",
                "- Common aggregation functions include average(mean), median, minimum(min), maximum(max), sum, standard deviation(std), variance(var), and count."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "3fc6aad2-ff89-4048-b89e-f17113f2c22d",
            "metadata": {
                "cellIdentifier": "3fc6aad2-ff89-4048-b89e-f17113f2c22d",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 192
                },
                "executionInfo": {
                    "elapsed": 407,
                    "status": "ok",
                    "timestamp": 1716270197354,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "3fc6aad2-ff89-4048-b89e-f17113f2c22d",
                "outputId": "f588c9cc-df7e-4cef-bd79-df287e8f8e9b",
                "tags": []
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Creating a DataFrame with a 'Category' column and a 'Value' column\n",
                "data = {'Category': ['A', 'B', 'A', 'B', 'A'],\n",
                "        'Value': [10, 15, 20, 25, 30]}\n",
                "df = pd.DataFrame(data)\n",
                "\n",
                "# Grouping the DataFrame by 'Category' and calculating various aggregations\n",
                "df_aggregated = df.groupby('Category').agg({\n",
                "    'Value': ['mean', 'median', 'min', 'max', 'sum', 'std', 'var', 'count']\n",
                "})\n",
                "\n",
                "# Displaying the aggregated DataFrame\n",
                "print(\"Aggregated DataFrame:\")\n",
                "df_aggregated"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e0ebf25b-787f-4abf-8b7b-e0df0be651ae",
            "metadata": {
                "cellIdentifier": "e0ebf25b-787f-4abf-8b7b-e0df0be651ae",
                "id": "e0ebf25b-787f-4abf-8b7b-e0df0be651ae"
            },
            "source": [
                "## __11. Reshaping Data__\n",
                "\n",
                "Reshaping data includes pivoting, melting, or stacking data to achieve a structure suitable for specific analyses or visualizations.\n",
                "\n",
                "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Reshaping_data.png)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "41c28961-e709-467d-9230-9122d6d36fa8",
            "metadata": {
                "cellIdentifier": "41c28961-e709-467d-9230-9122d6d36fa8",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 355,
                    "status": "ok",
                    "timestamp": 1716270206513,
                    "user": {
                        "displayName": "Ashish Jangid",
                        "userId": "15170006874299393728"
                    },
                    "user_tz": -330
                },
                "id": "41c28961-e709-467d-9230-9122d6d36fa8",
                "outputId": "8a52f2dd-3c3a-4c15-ad07-fcfa20fd50b5"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Assuming you have a DataFrame 'df' with 'Date', 'Category', and 'Value' columns\n",
                "# Adjust column names and DataFrame based on your actual data\n",
                "\n",
                "# DataFrame\n",
                "df = pd.DataFrame({'Date': ['2022-01-01', '2022-01-01', '2022-01-02', '2022-01-02'],\n",
                "                   'Category': ['A', 'B', 'A', 'B'],\n",
                "                   'Value': [10, 15, 20, 25]})\n",
                "\n",
                "# Pivoting data for better analysis\n",
                "df_pivoted = df.pivot_table(index='Date', columns='Category', values='Value', aggfunc='mean')\n",
                "\n",
                "# Displaying the pivoted DataFrame\n",
                "print(\"Pivoted DataFrame:\")\n",
                "print(df_pivoted)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c8267d0e-9f4d-4616-83a5-7944877caea7",
            "metadata": {
                "cellIdentifier": "c8267d0e-9f4d-4616-83a5-7944877caea7",
                "id": "c8267d0e-9f4d-4616-83a5-7944877caea7"
            },
            "source": [
                "# __Assisted Practice__"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1a949a7b-888c-4ce4-ba1b-c1c7fa798a55",
            "metadata": {
                "cellIdentifier": "1a949a7b-888c-4ce4-ba1b-c1c7fa798a55",
                "id": "1a949a7b-888c-4ce4-ba1b-c1c7fa798a55"
            },
            "source": [
                "## __Problem Statement:__\n",
                "\n",
                "The complexity of the housing market can be overwhelming. For a data scientist at a real estate company, the responsibility lies in analyzing housing data to uncover insights into house prices. The goal is to comprehend the elements influencing house prices and the impact of various house features on their price. This understanding aids the company in navigating the housing market more effectively and making well-informed decisions when purchasing and selling houses."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "58b44961-3afc-4323-9eef-7e0ac04c1eba",
            "metadata": {
                "cellIdentifier": "58b44961-3afc-4323-9eef-7e0ac04c1eba",
                "id": "58b44961-3afc-4323-9eef-7e0ac04c1eba"
            },
            "source": [
                "## __Steps to Perform:__\n",
                "\n",
                "- Understand the structure of the dataset, the types of variables, and any obvious issues in the data\n",
                "- Check for duplicate entries in the dataset and decide how to handle them\n",
                "- Identify and handle missing values. Decide whether to fill them in or drop them based on the context\n",
                "- Apply the necessary transformations to the variables. This could include scaling numerical variables or encoding categorical variables\n",
                "- For continuous variables, consider creating bins to turn them into categorical variables. For example, you can bin the __YearBuilt__ feature into decades\n",
                "- Identify outliers in the dataset and decide on a strategy to handle them. You can use a box plot to visualize outliers in features like __LotArea__ or __SalePrice__"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
